{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class NN:\n",
    "    def __init__(self, input_dim, hidden_dims, activations=None):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_dim : int\n",
    "            size of the input layer.\n",
    "        hidden_dims : LIST<int>\n",
    "            List of positive integers where each integer corresponds to the number of neurons \n",
    "            in the hidden layers. The list excludes the number of neurons in the output layer.\n",
    "            For this problem, we fix the output layer to have just 1 neuron.\n",
    "        activations : LIST<string>, optional\n",
    "            List of strings where each string corresponds to the activation function to be used \n",
    "            for all hidden layers. The list excludes the activation function for the output layer.\n",
    "            For this problem, we fix the output layer to have the sigmoid activation function.\n",
    "        ----------\n",
    "        Returns : None\n",
    "        ----------\n",
    "        '''\n",
    "        assert(len(hidden_dims) > 0)\n",
    "        assert(activations == None or len(hidden_dims) == len(activations))\n",
    "            \n",
    "        # If activations is None, we use sigmoid activation for all layers\n",
    "        # if activations == None:\n",
    "        #     self.activations = [sigmoid]*(len(hidden_dims)+1)\n",
    "        #     self.activation_derivatives = [sigmoid_derivative]*(len(hidden_dims)+1)\n",
    "        # else:\n",
    "        #     self.activations, self.activation_derivatives = get_activation_functions(activations + ['sigmoid'])\n",
    "\n",
    "        ## TODO 2: Initialize weights and biases for all hidden and output layers\n",
    "        ## Initialization can be done with random normal values, you are free to use\n",
    "        ## any other initialization technique.\n",
    "        \n",
    "        self.weights = [np.random.normal(0, 1, (input_dim, hidden_dims[0]))] + \\\n",
    "               [np.random.normal(0, 1, (hidden_dims[i - 1], hidden_dims[i])) for i in range(1, len(hidden_dims))] + \\\n",
    "               [np.random.normal(0, 1, (hidden_dims[-1], 1))]\n",
    "\n",
    "\n",
    "        self.biases = [np.random.normal(0, 1, (1, hidden_dims[i])) for i in range(len(hidden_dims))] +\\\n",
    "                       [np.random.normal(0, 1, (1, 1))]\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.36527135, -1.50683359],\n",
      "       [ 0.35244573,  0.77493699],\n",
      "       [ 0.60804564, -0.99725164],\n",
      "       [-0.41824208, -0.64396977]]), array([[ 1.50536283,  0.56240812,  0.23342739],\n",
      "       [ 1.19123817, -0.60464507, -1.14524746]]), array([[-1.41127706],\n",
      "       [-0.12457796],\n",
      "       [-0.96843596]])]\n",
      "[array([[-0.23372635,  0.63322397]]), array([[-0.9563355 , -0.16604245,  1.39405692]]), array([[0.93288599]])]\n"
     ]
    }
   ],
   "source": [
    "nn = NN(4,[2,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
